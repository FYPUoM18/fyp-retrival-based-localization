{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a86f065",
   "metadata": {},
   "source": [
    "# Simple Siamese Network Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414eb447",
   "metadata": {},
   "source": [
    "Implementation is done to get understanding of how contrastive learn work, which will help to implement FYP project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56be0cda",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e27f2",
   "metadata": {},
   "source": [
    "Used AT&T Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7c6f1f",
   "metadata": {},
   "source": [
    "Can Be Found At : https://www.kaggle.com/datasets/kasikrit/att-database-of-faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44510ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_PATH = \"att_data/training\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60b22b5",
   "metadata": {},
   "source": [
    "### Configure and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a4351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318b91e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35842748",
   "metadata": {},
   "source": [
    "### Preparing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef27dc3",
   "metadata": {},
   "source": [
    "There are three persons in dataset. And each one containing 10 images. In order to train good neural network we need to precent class imbalance. Where we need to choose pair of images such that, 50% of images related to person and 50% images related to different person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c384d958",
   "metadata": {},
   "source": [
    "Let's list all image paths and give tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46f7da2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 50,  49,  50,  ...,  41,  42,  38],\n",
       "          [ 55,  46,  50,  ...,  39,  39,  36],\n",
       "          [ 50,  49,  49,  ...,  37,  42,  38],\n",
       "          ...,\n",
       "          [183, 165, 145,  ..., 118, 114, 105],\n",
       "          [133, 148, 155,  ..., 120, 118, 116],\n",
       "          [144, 150, 169,  ..., 159, 111, 117]]], dtype=torch.uint8),\n",
       " 's14')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_of_training_directory = os.listdir(TRAINING_PATH)\n",
    "img_dict = []\n",
    "\n",
    "for tag in content_of_training_directory:\n",
    "    \n",
    "    images_under_tag = os.listdir(TRAINING_PATH+\"/\"+tag)\n",
    "    \n",
    "    for image in images_under_tag:\n",
    "        \n",
    "        image_location = TRAINING_PATH+\"/\"+tag+\"/\"+image\n",
    "        img = Image.open(image_location)\n",
    "        \n",
    "        img.convert(\"L\")\n",
    "        img.resize((100,100))\n",
    "        \n",
    "        transform = transforms.Compose([transforms.PILToTensor()])\n",
    "        tensor = transform(img)\n",
    "        img_dict.append((tensor, tag))\n",
    "\n",
    "random.shuffle(img_dict)\n",
    "img_dict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f328252",
   "metadata": {},
   "source": [
    "Image Dict Contain Images And Tag as (PIL_IMAGE, TAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae499a6",
   "metadata": {},
   "source": [
    "Now we need to make a batch with 50% similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56347486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_a_batch(batchsize):\n",
    "    \n",
    "    # Content -> List Of (Image_1_Tensor, Image_2_Tensor, Is_Similar_Boolean)\n",
    "    output_list = []\n",
    "    \n",
    "    # Select Similar Images\n",
    "    for i in range(batchsize//2):\n",
    "        img_1 = random.choice(img_dict)\n",
    "        while True:\n",
    "            img_2 = random.choice(img_dict)\n",
    "            if img_1[1]==img_2[1]:\n",
    "                output_list.append((img_1,img_2,True))\n",
    "                break\n",
    "    \n",
    "    # Select Dissimilar Images\n",
    "    for i in range(batchsize//2,batchsize):\n",
    "        img_1 = random.choice(img_dict)\n",
    "        while True:\n",
    "            img_2 = random.choice(img_dict)\n",
    "            if img_1[1]!=img_2[1]:\n",
    "                output_list.append((img_1,img_2,False))\n",
    "                break\n",
    "    \n",
    "    # Shuffle\n",
    "    random.shuffle(output_list)\n",
    "    \n",
    "    # Return\n",
    "    return output_list\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef147cfa",
   "metadata": {},
   "source": [
    "We need a function to view a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d09e5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(load_a_batch(21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139337c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
